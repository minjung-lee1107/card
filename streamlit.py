import streamlit as st
import pandas as pd
import plotly.express as px
from openai import OpenAI
import re
import json
import difflib


# -----ë°ì´í„° ì „ì²˜ë¦¬-----

## ì¹´í…Œê³ ë¦¬ ìë™ë¶„ë¥˜

RULES = {
    "ì‹ë¹„": ["ì‹ë‹¹", "ì¹´í˜", "ì»¤í”¼", "ì¹˜í‚¨", "í”¼ì", "ë¶„ì‹", "ê¹€ë°¥", "êµ­ë°¥", "ë²„ê±°", "ì œê³¼", "ë² ì´ì»¤ë¦¬", "ë°°ë‹¬", "ë„ì‹œë½"],
    "ê¸ˆìœµ/ë³´í—˜": ["ë³´í—˜", "ì†ë³´", "í™”ì¬", "ìƒëª…", "ëŒ€ì¶œ", "ì´ì"],
    "ì˜ë£Œ/ê±´ê°•": ["ë³‘ì›", "ì˜ì›", "ì•½êµ­", "ì¹˜ê³¼", "í•œì˜ì›", "ê²€ì§„", "í—¬ìŠ¤", "í•„ë¼í…ŒìŠ¤","GYM"],
    "êµí†µ": ["ì£¼ì°¨", "íƒì‹œ", "ë²„ìŠ¤", "ì§€í•˜ì² ", "ì£¼ìœ ", "ì •ë¹„", "í†¨ê²Œì´íŠ¸", "ê³ ì†ë„ë¡œ"],
    "ì‡¼í•‘": ["ë§ˆíŠ¸", "í¸ì˜ì ", "ë°±í™”ì ", "ì•„ìš¸ë ›", "ë‹¤ì´ì†Œ", "ì˜¬ë¦¬ë¸Œì˜","ì¿ íŒ¡","ì¿ íŒ¡(ì¿ í˜ì´)"],
    "ì£¼ê±°/í†µì‹ ": ["ê´€ë¦¬ë¹„", "ì›”ì„¸", "ê°€ìŠ¤", "ì „ê¸°", "ìˆ˜ë„", "í†µì‹ ", "ì¸í„°ë„·", "kt", "skt", "ìœ í”ŒëŸ¬ìŠ¤"],
    "êµ¬ë…": ["ë„·í”Œë¦­ìŠ¤", "netflix", "ìœ íŠœë¸Œ", "youtube", "ë©œë¡ ", "spotify", "ì• í”Œ", "google one"],
    "ë¬¸í™”/ì—¬ê°€": ["ì˜í™”", "cgv", "ë©”ê°€ë°•ìŠ¤", "ë¡¯ë°ì‹œë„¤ë§ˆ", "ê³µì—°", "ì „ì‹œ", "ì—¬í–‰", "ìˆ™ë°•", "í˜¸í…”", "ë†€ì´ê³µì›","íˆ¬ì–´"],
}
CATEGORIES = ["ì‹ë¹„","êµí†µ","ì‡¼í•‘","ì£¼ê±°/í†µì‹ ","êµ¬ë…","ì˜ë£Œ/ê±´ê°•","ë¬¸í™”/ì—¬ê°€","ê¸ˆìœµ/ë³´í—˜","ê¸°íƒ€"]

## ì»¬ëŸ¼ëª… ì •ê·œí™”
def _norm_col(x: str) -> str:
    """ì»¬ëŸ¼ëª… ë¹„êµìš© ì •ê·œí™”: ì†Œë¬¸ì, ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ì œê±°"""
    s = "" if x is None else str(x)
    s = s.strip().lower()
    s = re.sub(r"\s+", "", s)
    s = re.sub(r"[^0-9a-zA-Zê°€-í£_]", "", s)
    return s

def normalize_text(x):
    s = "" if pd.isna(x) else str(x)
    s = s.strip().lower()
    s = re.sub(r"\s+", " ", s)
    return s

## ê·œì¹™ì„ ê¸°ë°˜í•œ ì¹´í…Œê³ ë¦¬
def rule_category(description: str) -> str:
    d = normalize_text(description)
    if not d:
        return "ë¯¸ë¶„ë¥˜"
    for cat, keywords in RULES.items():
        for kw in keywords:
            if normalize_text(kw) in d:
                return cat
    return "ë¯¸ë¶„ë¥˜"

## AI ì¹´í…Œê³ ë¦¬
def ai_category_batch(descriptions, api_key, model="gpt-4o-mini"):
    descriptions = list(descriptions)
    if not descriptions:
        return {}

    client = OpenAI(api_key=api_key)
    prompt = f"""
ë„ˆëŠ” ì¹´ë“œ ì§€ì¶œì˜ ì„¤ëª…(description)ì„ ì§€ì¶œ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•œë‹¤.
ì¹´í…Œê³ ë¦¬ëŠ” ë°˜ë“œì‹œ ì•„ë˜ ì¤‘ í•˜ë‚˜ë§Œ ì‚¬ìš©:
{", ".join(CATEGORIES)}

ê·œì¹™:
- ì• ë§¤í•˜ë©´ "ê¸°íƒ€"
- ì¶œë ¥ì€ JSONë§Œ. ì˜ˆ: {{"ê°€ë§¹ì A":"ì‹ë¹„","ê°€ë§¹ì B":"êµí†µ"}}
- í‚¤ëŠ” ì…ë ¥ description ë¬¸ìì—´ ê·¸ëŒ€ë¡œ ì‚¬ìš©

description ëª©ë¡:
{json.dumps(descriptions, ensure_ascii=False)}
""".strip()

    res = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )
    txt = res.choices[0].message.content.strip()

    try:
        data = json.loads(txt)
    except json.JSONDecodeError:
        start, end = txt.find("{"), txt.rfind("}")
        data = json.loads(txt[start:end+1])

    out = {}
    for k, v in data.items():
        out[k] = v if v in CATEGORIES else "ê¸°íƒ€"
    return out

def build_category(df, api_key, desc_col="description"):
    ### 1. ê·œì¹™
    df["category_rule"] = df[desc_col].apply(rule_category)

    ### 2. ë¯¸ë¶„ë¥˜ë§Œ AI
    targets = df.loc[df["category_rule"]=="ë¯¸ë¶„ë¥˜", desc_col].dropna().astype(str).unique()
    ai_map = ai_category_batch(targets, api_key=api_key)

    ### 3. ìµœì¢…
    df["category"] = df.apply(
        lambda r: r["category_rule"] if r["category_rule"]!="ë¯¸ë¶„ë¥˜"
        else ai_map.get(str(r[desc_col]), "ê¸°íƒ€"),
        axis=1
    )
    return df

## ì»¬ëŸ¼ëª… ìë™ ë§¤í•‘
STANDARD_COLS = [
    "date", "amount", "category", "description",
    "sub_category", "payment_method", "is_fixed",
    "installment_type", "installment_months"
]
REQUIRED_COLS = ["date", "amount", "category", "description"]

## ë™ì˜ì–´
SYNONYMS = {
    "date": [
        "date","ê±°ë˜ì¼","ê±°ë˜ì¼ì","ìŠ¹ì¸ì¼","ìŠ¹ì¸ì¼ì","ê²°ì œì¼","ê²°ì œì¼ì","ì‚¬ìš©ì¼","ì‚¬ìš©ì¼ì","ì´ìš©ì¼","ì´ìš©ì¼ì","ë‚ ì§œ","ì¼ì"
    ],
    "amount": [
        "amount","ê¸ˆì•¡","ê²°ì œê¸ˆì•¡","ì‚¬ìš©ê¸ˆì•¡","ì´ìš©ê¸ˆì•¡","ìŠ¹ì¸ê¸ˆì•¡","ì²­êµ¬ê¸ˆì•¡","ì§€ì¶œ","ì§€ì¶œì•¡","ê¸ˆì•¡ì›","ì›ê¸ˆì•¡","êµ­ë‚´ì´ìš©ê¸ˆì•¡"
    ],
    "category": [
        "category","ì¹´í…Œê³ ë¦¬","ë¶„ë¥˜","ëŒ€ë¶„ë¥˜","ìƒìœ„ì¹´í…Œê³ ë¦¬","ì§€ì¶œë¶„ë¥˜"
    ],
    "description": [
        "description","ë‚´ì—­","ê±°ë˜ë‚´ì—­","ì‚¬ìš©ë‚´ì—­","ì´ìš©ë‚´ì—­","ê°€ë§¹ì ","ê°€ë§¹ì ëª…","ìƒí˜¸","ìƒí˜¸ëª…","ë‚´ìš©","ì ìš”","ë©”ëª¨","ìƒí’ˆëª…","ì´ìš©í•˜ì‹ ê³³"
    ],
    "sub_category": [
        "sub_category","subcategory","ì„¸ë¶€ì¹´í…Œê³ ë¦¬","ì†Œë¶„ë¥˜","í•˜ìœ„ì¹´í…Œê³ ë¦¬","ì„¸ë¶€ë¶„ë¥˜"
    ],
    "payment_method": [
        "payment_method","ê²°ì œìˆ˜ë‹¨","ì§€ë¶ˆìˆ˜ë‹¨","ì§€ë¶ˆìˆ˜ë‹¨","ì¹´ë“œì¢…ë¥˜","ìˆ˜ë‹¨"
    ],
    "is_fixed": [
        "is_fixed","ê³ ì •ë¹„","ê³ ì •ì§€ì¶œ","ì •ê¸°","ì •ê¸°ê²°ì œ","ê³ ì •ì—¬ë¶€","ê³ ì •ë¹„ì—¬ë¶€"
    ],
    "installment_type": [
        "installment_type","í• ë¶€ìœ í˜•","ê²°ì œë°©ì‹","ì¼ì‹œë¶ˆí• ë¶€","í• ë¶€êµ¬ë¶„","í• ë¶€ì—¬ë¶€","ê²°ì œìœ í˜•","ê²°ì œë°©ë²•"
    ],
    "installment_months": [
        "installment_months","í• ë¶€ê°œì›”","í• ë¶€ê°œì›”ìˆ˜","í• ë¶€ê¸°ê°„","í• ë¶€ê°œì›”ìˆ˜","ê°œì›”","í• ë¶€ì›”","í• ë¶€"
    ],
}

def auto_map_columns(df: pd.DataFrame):
    """
    dfì˜ ì»¬ëŸ¼ì„ í‘œì¤€ ì»¬ëŸ¼ìœ¼ë¡œ ìë™ ë§¤í•‘.
    - 1ì°¨: SYNONYMS ì‚¬ì „ ê¸°ë°˜
    - 2ì°¨: difflib ìœ ì‚¬ë„ ê¸°ë°˜(ì‚¬ì „ì— ì—†ëŠ” ê²½ìš°)
    ë°˜í™˜: (df_renamed, mapping, dropped_cols)
    """
    original_cols = list(df.columns)
    norm_to_orig = { _norm_col(c): c for c in original_cols }

    ### ì‚¬ì „ ê¸°ë°˜ ë§¤í•‘
    mapping = {}
    used_original = set()

    for std, syns in SYNONYMS.items():
        ### í‘œì¤€ëª… ìì²´ë„ ë™ì˜ì–´ì²˜ëŸ¼ ì·¨ê¸‰
        candidates = [_norm_col(x) for x in ([std] + syns)]
        hit = None
        for cand in candidates:
            if cand in norm_to_orig:
                hit = norm_to_orig[cand]
                break
        if hit and hit not in used_original:
            mapping[hit] = std
            used_original.add(hit)

    ### ìœ ì‚¬ë„ ê¸°ë°˜ ë³´ì™„
    remaining_std = [c for c in STANDARD_COLS if c not in set(mapping.values())]
    remaining_orig = [c for c in original_cols if c not in mapping]

    for std in remaining_std:
        
        orig_norms = [_norm_col(c) for c in remaining_orig]
        
        target = _norm_col(std)
        matches = difflib.get_close_matches(target, orig_norms, n=1, cutoff=0.86)
        if matches:
            norm_hit = matches[0]
            orig_hit = norm_to_orig[norm_hit]
            if orig_hit not in mapping:
                mapping[orig_hit] = std
                remaining_orig.remove(orig_hit)

    ### rename ì ìš©
    df2 = df.rename(columns=mapping).copy()

    ## í‘œì¤€ ìŠ¤í‚¤ë§ˆ ì´ì™¸ drop
    dropped = [c for c in df2.columns if c not in STANDARD_COLS]
    df2 = df2.drop(columns=dropped, errors="ignore")

    return df2, mapping, dropped

## íƒ€ì… ì •ë¦¬
def coerce_types(df: pd.DataFrame) -> pd.DataFrame:
    ### date
    if "date" in df.columns:
        df["date"] = pd.to_datetime(df["date"], errors="coerce")
        df = df.dropna(subset=["date"])

    ### amount
    if "amount" in df.columns:
        df["amount"] = (
            df["amount"]
            .astype(str)
            .str.replace(",", "", regex=False)
            .str.replace("ì›", "", regex=False)
            .str.strip()
        )
        df["amount"] = pd.to_numeric(df["amount"], errors="coerce")
        df = df.dropna(subset=["amount"])

    ### is_fixed
    if "is_fixed" in df.columns:
        def _to_bool(x):
            if pd.isna(x):
                return False
            s = str(x).strip().lower()
            if s in ["true", "1", "y", "yes", "t", "ê³ ì •", "ì •ê¸°", "o", "ã…‡"]:
                return True
            if s in ["false", "0", "n", "no", "f", "x", "ë¹„ê³ ì •", "ì¼íšŒ", "", "nan"]:
                return False
            return False

        df["is_fixed"] = df["is_fixed"].apply(_to_bool)


    ### installment_type / installment_months
    def normalize_installment(row):
        itype = row.get("installment_type", pd.NA)
        months = row.get("installment_months", pd.NA)

        ### installment_typeì— ìˆ«ìê°€ ìˆëŠ” ê²½ìš°
        if not pd.isna(itype):
            s = str(itype).strip()
            if s.isdigit():
                m = int(s)
                if m <= 1:
                    return "ì¼ì‹œë¶ˆ", pd.NA
                else:
                    return "í• ë¶€", m

        ### ê¸°ì¡´ í…ìŠ¤íŠ¸ ê¸°ë°˜ íŒë‹¨
        s_low = str(itype).lower() if not pd.isna(itype) else ""

        if "í• ë¶€" in s_low or "install" in s_low:
            m = pd.to_numeric(months, errors="coerce")
            return "í• ë¶€", m if (pd.notna(m) and m > 1) else pd.NA

        ### ê¸°ë³¸ê°’
        return "ì¼ì‹œë¶ˆ", pd.NA


    ### ì»¬ëŸ¼ ìˆìœ¼ë©´ ì ìš©
    if "installment_type" in df.columns:
        df[["installment_type", "installment_months"]] = df.apply(
            normalize_installment,
            axis=1,
            result_type="expand"
        )


    ### category / description / string ê³„ì—´
    for col in ["category", "description", "sub_category", "payment_method"]:
        if col in df.columns:
            df[col] = df[col].astype(str).str.strip()
            df.loc[df[col].isin(["", "nan", "None"]), col] = pd.NA


    return df


## ìµœì¢… ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
def preprocess_any_expense_df(df: pd.DataFrame, api_key: str):
    """
    1) ì»¬ëŸ¼ ìë™ ë§¤í•‘ + drop
    2) íƒ€ì… ê°•ì œ
    3) í•„ìˆ˜ ì»¬ëŸ¼ ë³´ì •/ê²€ì‚¬
    4) category ì—†ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ ìƒì„±(ê·œì¹™â†’ë¯¸ë¶„ë¥˜ë§Œ AI)
    5) month/year_month ìƒì„±
    ë°˜í™˜: df_final, report(dict)
    """
    report = {}

    df1, mapping, dropped = auto_map_columns(df)
    report["column_mapping"] = mapping
    report["dropped_columns"] = dropped
    report["columns_after_mapping"] = list(df1.columns)

    df2 = coerce_types(df1)

    ### í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
    missing_required = [c for c in ["date","amount","description"] if c not in df2.columns]
    if missing_required:
        report["missing_columns"] = missing_required
        report["error_type"] = "missing_required_columns"
        return None, report

    ### category ì²˜ë¦¬: ì—†ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ ìƒì„±
    if "category" not in df2.columns:
        df2["category"] = pd.NA

    ### category ë¹„ì–´ìˆê±°ë‚˜ ë¯¸ë¶„ë¥˜ë©´ ìƒì„±
    need_cat = df2["category"].isna() | (df2["category"].astype(str).str.strip() == "") | (df2["category"] == "ë¯¸ë¶„ë¥˜")
    if need_cat.any():
        tmp = df2.copy()
        ### build_categoryëŠ” description ê¸°ë°˜ìœ¼ë¡œ category ìƒì„±í•˜ê¸° ë•Œë¬¸ì— ì „ì²´ë¥¼ ë„£ê³  ë®ì–´ì“°ê¸°
        tmp = build_category(tmp, api_key=api_key, desc_col="description")
        df2.loc[need_cat, "category"] = tmp.loc[need_cat, "category"]

    ### category ê°’ í‘œì¤€í™”
    df2["category"] = df2["category"].apply(lambda x: x if x in CATEGORIES else "ê¸°íƒ€")

    ### month/year_month ìƒì„±
    df2["month"] = df2["date"].dt.to_period("M").astype(str)
    df2["year_month"] = df2["date"].dt.strftime("%Y-%m")

    ### ì»¬ëŸ¼ ìˆœì„œ ì •ë ¬
    ordered = [c for c in STANDARD_COLS if c in df2.columns] + ["month","year_month"]
    df2 = df2[ordered]

    report["rows_final"] = len(df2)
    return df2, report


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ’° ê°œì¸ ì§€ì¶œ ë¶„ì„",
    page_icon="ğŸ’°",
    layout="wide"
)

st.title("ğŸ’° ê°œì¸ ì§€ì¶œ ë¶„ì„")

# ì‚¬ì´ë“œë°” - íŒŒì¼ ì—…ë¡œë“œ
with st.sidebar:
    st.header("ğŸ“ ë°ì´í„° ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader(
        "CSV ë˜ëŠ” Excel íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
        type=['csv', 'xlsx', 'xls']
    )

# ë©”ì¸ ì˜ì—­
if uploaded_file is not None:
    try:
        ## íŒŒì¼ ì½ê¸°
        if uploaded_file.name.endswith('.csv'):
            try:
                df_raw = pd.read_csv(uploaded_file, encoding='utf-8')
            except UnicodeDecodeError:
                uploaded_file.seek(0)
                df_raw = pd.read_csv(uploaded_file, encoding='cp949')
        else:
            df_raw = pd.read_excel(uploaded_file)

        ## ì „ì²˜ë¦¬ ì‹¤í–‰
        df, prep_report = preprocess_any_expense_df(
            df_raw,
            api_key=st.secrets["OPENAI_API_KEY"]
        )

        # ì „ì²˜ë¦¬ ì‹¤íŒ¨ì‹œ ì‚¬ìš©ìì—ê²Œ ì•ˆë‚´
        if df is None:
            st.error("âŒ í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ì–´ ì „ì²˜ë¦¬ë¥¼ ì§„í–‰í•  ìˆ˜ ì—†ì–´ìš”.")
            st.markdown(
                f"""
        **ëˆ„ë½ëœ í•„ìˆ˜ ì»¬ëŸ¼:** `{', '.join(prep_report['missing_columns'])}`

        ğŸ‘‰ íŒŒì¼ì— **ê±°ë˜ì¼ / ê¸ˆì•¡ / ë‚´ì—­**ì— í•´ë‹¹í•˜ëŠ” ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.

        ì»¬ëŸ¼ëª…ì€ ì •í™•íˆ ì¼ì¹˜í•˜ì§€ ì•Šì•„ë„ ê´œì°®ì•„ìš”.  
        ì˜ˆë¥¼ ë“¤ì–´,  
        - ì´ìš©ì¼ â†’ `ê±°ë˜ì¼`, `ê²°ì œì¼`, `ìŠ¹ì¸ì¼ì`
        - ê±°ë˜ê¸ˆì•¡ â†’ `ê¸ˆì•¡`, `ì‚¬ìš©ê¸ˆì•¡`, `ê²°ì œê¸ˆì•¡`
        - ì´ìš©í•˜ì‹ ê³³ â†’ `ê±°ë˜ë‚´ì—­`, `ì‚¬ìš©ë‚´ì—­`, `ê°€ë§¹ì ëª…`

        ì²˜ëŸ¼ ë˜ì–´ ìˆì–´ë„ ìë™ìœ¼ë¡œ ì¸ì‹ë¼ìš” ğŸ™‚  
        ì»¬ëŸ¼ëª…ì„ ìˆ˜ì •í•œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.
        """
            )

            with st.expander("ğŸ” ìë™ ë§¤í•‘ ê²°ê³¼ ë³´ê¸°"):
                st.write(prep_report["column_mapping"])

            st.stop()


        st.success(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ! ({prep_report['rows_final']}ê±´)")

        ## ë§¤í•‘ ê²°ê³¼ í™•ì¸ìš©
        with st.expander("ğŸ§© ì»¬ëŸ¼ ìë™ ë§¤í•‘ ê²°ê³¼"):
            st.write(prep_report["column_mapping"])

        with st.expander("ğŸ—‘ï¸ ì‚­ì œëœ ì»¬ëŸ¼"):
            st.write(prep_report["dropped_columns"])

        with st.expander("ğŸ“‹ ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
            st.dataframe(df.head(10))

    except Exception as e:
        st.error(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
    
else:
    st.info("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    
    st.markdown(" ")
    st.markdown(" ")
    st.markdown(" ")

    ## ì¹´ë“œë¡œ í•µì‹¬ ê¸°ëŠ¥ ì„¤ëª…
    c1, c2, c3 = st.columns(3) 
        
    with c1: 
        st.markdown("## ğŸ§¹ ìë™ ì „ì²˜ë¦¬") 
        st.caption("ê±°ë˜ì¼/ê¸ˆì•¡/ë‚´ì—­ ì»¬ëŸ¼ì„ ìë™ ì¸ì‹í•˜ê³  í‘œì¤€ í¬ë§·ìœ¼ë¡œ ì •ë¦¬í•´ìš”.") 
        
    with c2: 
        st.markdown("## ğŸ§© ë§¤í•‘ ê²°ê³¼ ë¦¬í¬íŠ¸") 
        st.caption("ì›ë³¸ ì»¬ëŸ¼ì´ ì–´ë–¤ í•„ë“œë¡œ ë§¤í•‘ëëŠ”ì§€ íˆ¬ëª…í•˜ê²Œ ë³´ì—¬ì¤˜ìš”.") 
        
    with c3: 
        st.markdown("## ğŸ“Š ë¶„ì„ & ì¸ì‚¬ì´íŠ¸") 
        st.caption("ì›”ë³„/ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„ê³¼ AI ìš”ì•½ì„ ì œê³µí•´ìš”.") 
    
    st.markdown(" ")
    st.markdown(" ")
    st.markdown(" ")


    st.markdown("## ğŸš€ ì‚¬ìš© ë°©ë²•") 
    st.markdown(
        """ 
        1. ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ **CSV/Excel** íŒŒì¼ ì—…ë¡œë“œ 
        2. ìë™ ì „ì²˜ë¦¬ ì™„ë£Œ í›„, **ë¯¸ë¦¬ë³´ê¸°/ë§¤í•‘ ê²°ê³¼** í™•ì¸ 
        3. ë¶„ì„/ë¦¬í¬íŠ¸ ìƒì„± ë²„íŠ¼ìœ¼ë¡œ ê²°ê³¼ í™•ì¸ 
        """ 
        )

    st.markdown(" ")
    st.markdown(" ")
    st.markdown(" ")
    
    tab1, tab2 = st.tabs(["ğŸ“„ ì—…ë¡œë“œ ì˜ˆì‹œ", "â“ FAQ"])

    with tab1:
        st.markdown(
            """
            **íŒŒì¼ì— ì´ëŸ° í˜•íƒœê°€ ë“¤ì–´ìˆìœ¼ë©´ ì¢‹ì•„ìš”**
            - ê±°ë˜ì¼: 2026-02-03 / 2026.02.03 / 2026/02/03
            - ê¸ˆì•¡: 15000 / -15000(í™˜ë¶ˆ) ë“±
            - ë‚´ì—­: ìŠ¤íƒ€ë²…ìŠ¤ ì•„ë©”ë¦¬ì¹´ë…¸, ì¿ íŒ¡, ì§€í•˜ì²  ë“±
            """
        )

    with tab2:
        st.markdown(
            """
            **Q. ì»¬ëŸ¼ëª…ì´ ê¼­ 'ê±°ë˜ì¼/ê¸ˆì•¡/ë‚´ì—­'ì´ì–´ì•¼ í•˜ë‚˜ìš”?**  
            A. ì•„ë‹ˆìš”! ë¹„ìŠ·í•œ ì˜ë¯¸ë©´ ìë™ìœ¼ë¡œ ë§¤í•‘í•´ìš”.

            **Q. ì—…ë¡œë“œí•œ íŒŒì¼ì€ ì €ì¥ë˜ë‚˜ìš”?**  
            A. ì•„ë‹ˆìš”! ë”°ë¡œ ì €ì¥ë˜ì§€ëŠ” ì•Šì•„ìš”.
            """
        )